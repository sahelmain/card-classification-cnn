
1
CS 5388 Project Report: Classification of Cards by Implementing Convolutional
Neural Networks (CNNs)
Baris Ozcan
Texas Tech University
bzcan@ttu.edu
R11967437
Nameera Khan
Texas Tech University
namkhan@ttu.edu
R11965493
Namra Khan
Texas Tech University
namrkhan@ttu.edu
R11965577
Sahel Azzam
Texas Tech University
saazzam@ttu.edu
R11814223
Abstract
Card classification from images is a fundamental com-
puter vision task with applications in gaming, automation,
and augmented reality. This study investigates the effec-
tiveness of deep learning approaches for automated playing
card recognition. This study presents a comparative anal-
ysis of two convolutional neural network (CNN) architec-
tures for the classification of standard playing cards from
image data which are a custom-designed sequential CNN
and a pre-trained EfficientNet-B0 model. The dataset con-
sists of 8,154 high-resolution images uniformly distributed
across 53 card classes. The custom CNN model was trained
from scratch, incorporating standard convolutional and
pooling layers with dropout for regularization. On the other
hand, the EfficientNet-B0 model was fine-tuned using trans-
fer learning techniques to use features learned from large-
scale datasets. This study shows advantages of transfer
learning for card recognition tasks. It offers a reproducible
benchmark for future studies in domain-specific image clas-
sification.
1. Introduction/Background/Motivation
We taught a computer how to recognize and label dif-
ferent playing cards just by looking at pictures of the card.
Our goal was to build a system that can look at an image
of a card and correctly tell which card it is, like ”Ace of
Spades” or ”3 of Hearts,” using only the picture.
Firstly, we collected many clear images of playing cards.
We then trained a model by showing it many of these pic-
tures, along with the correct name for each card.
We built a simpler model from scratch using the Se-
quential method. This model had fewer layers and was
trained entirely on the playing card images we provided.
This helped us understand how well a custom-designed net-
work could perform compared to a pre-trained one. Second
phase, we used a pre-trained model which is EfficientNet
[5][1]. We fine-tuned this model using our playing card im-
ages. This means we adjusted the model’s existing knowl-
edge to make it better at identifying playing cards. In the
scope of our project, we compare their results to discuss
methods in terms of classification accuracy and computa-
tional cost.
Recent research has explored various approaches to play-
ing card classification. Mittal et al. study to classify and
detect how one plays cards specifically using deep learning
technique [3]. They developed a CNN that is designed to
identify the rank and suit of playing cards by using their im-
age. Synder proposes a approach to classify playing cards
[4]. His SIFT-based feature matching technique detect and
identify playing cards from static images. This method
achieve 98% accuracy under the best possible conditions.
However, it has limitations due to the symmetrical features
of playing cards. Apiletti et al. proposed a data mining-
based decision support system that employs classification
algorithms such as decision trees, Naive Bayes, and SVMs
[2]. While their core objective is to accurately classify cards
based on learned patterns, they specifically focus on the
context of poker. These studies collectively illustrate that
current methods have evolved from hand-engineered fea-
tures to deep learning architectures. However, deep learning
methods have challenges persist in handling symmetric vi-
sual patterns, variable lighting, and real-time classification
1
needs.
Reliable card recognition models have potential to im-
pact amany domains. Casino surveillance departments can
flag marked or swapped cards in milliseconds, cutting an-
nual losses from cheating events. Automated card dealers
and sorting robots may gain a robust perception module
that tolerates glare and partial occlusion. Augmented-reality
game developers can embed a classifier for offline playing
on mobile devices. the academic community obtains bene-
fits from a publicly accessible benchmark for developing a
model to specifically specializes in card recognition tasks.
Data Sheet
• Purpose: This dataset was collected to support deep
learning models in recognizing and classifying play-
ing card types based on images. It addresses the need
for a high-quality image dataset specific to standard
playing cards for applications such as object detection,
augmented reality, and computer vision-based games.
Our group downloaded this dataset from open source
to using it in accordance with the purpose of creation.
Composition
• Instances: Each instance represents a color image of
a single playing card.
• Total Count: 8,154 images (7,624 training, 265 vali-
dation, 265 testing)
• Sampling: The dataset is not a random sample. It is a
curated collection where each class of playing card is
uniformly represented across the train, validation, and
test sets.
• Instance Content: JPEG images of resolution
224x224 pixels with 3 color channels (RGB).
• Labels: Each image is labeled according to one of the
53 unique card types (including jokers).
• Data Splits: Train, validation, and test sets are pro-
vided as separate folders with 53 subdirectories each,
corresponding to card types.
Collection Process
• Data Acquisition: The images were directly captured
using a camera.
• Collection Method: Our team gathered data from an
open-source website named Kaggle.
• Timeframe: The dataset was downloaded on March
31, 2025.
Preprocessing, Cleaning, and Labeling
• Preprocessing: Each image was cropped to ensure the
card occupies over 50
• Labeling: Labels were defined based on existing di-
rectory structure.
• Software: Preprocessing scripts were written in
Python.
Uses
• Current Uses: Classification and computer vision
tasks involving card recognition.
• Potential Uses: AR card games, card sorting robots,
training for any card classification pipelines.
Distribution
• Availability: https://www.kaggle.
com/datasets/gpiosenka/
cards-image-datasetclassification
• License: CC0: Public Domain
• Restrictions: Open Source
2. Methodology and Approach
In this section, we describe the key stages of the project,
from data collection to model evaluation.
2.1. Data Access and Preparation
To start, we initially handled dataset from Kaggle. Then,
for using dataset in colab platform, dataset was a ZIP file
called cards.zip stored on Google Drive. We mounted
Google Drive, extracted the contents of the ZIP file into a
folder called cards extracted, and prepared it for fur-
ther processing.
After that, we defined the paths for the training, valida-
tion, and test datasets, which helped us organize the data
properly. We made sure to use the correct folders for each
stage of data analysis and model training.
2.2. Data Preprocessing
Next, we moved on to data preprocessing to get our im-
ages ready for model training. The images were resized to
a uniform shape of 200x200 pixels. Resizing helped stan-
dardize the input size for both models, making it easier for
the network to process.
We also normalized the images by scaling the pixel
values to the range [0, 1]. This was done using an
ImageDataGenerator with the rescale=1./255
